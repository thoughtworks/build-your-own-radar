name,ring,quadrant,isNew,description
Applying product management to internal platforms,Adopt,Techniques,FALSE,"<p>More and more companies are building internal platforms to roll out new digital solutions quickly and efficiently. Companies that succeed with this strategy are <strong>applying product management to internal platforms</strong>. This means establishing empathy with internal consumers (the development teams) and collaborating with them on the design. Platform product managers create roadmaps and ensure the platform delivers value to the business and enhances the developer experience. Unfortunately, we're also seeing less successful approaches, where teams create a platform in the void, based on unverified assumptions and without internal customers. These platforms, often despite aggressive internal tactics, end up being underutilized and a drain on the organization's delivery capability. As usual, good product management is all about building products that consumers love.</p>"
Infrastructure as code,Adopt,Techniques,FALSE,"<p>Although <strong>infrastructure as code</strong> is a relatively old technique (we’ve featured it in the Radar in 2011), it has become vitally important in the modern cloud era where the act of setting up infrastructure has become the passing of configuration instructions to a cloud platform. When we say ""as code"" we mean that all the good practices we've learned in the software world should be applied to infrastructure. Using source control, adhering to the <a href=""https://en.wikipedia.org/wiki/Don%27t_repeat_yourself"">DRY principle</a>, modularization, maintainability, and using automated testing and deployment are all critical practices. Those of us with a deep software and infrastructure background need to empathize with and support colleagues who do not. Saying ""treat infrastructure like code"" isn't enough; we need to ensure the hard-won learnings from the software world are also applied consistently throughout the infrastructure realm.</p>"
Micro frontends,Adopt,Techniques,FALSE,"<p>We've seen significant benefits from introducing <a href=""https://martinfowler.com/articles/microservices.html"">microservices</a>, which have allowed teams to scale the delivery of independently deployed and maintained services. Unfortunately, we've also seen many teams create a front-end monolith — a large, entangled browser application that sits on top of the back-end services — largely neutralizing the benefits of microservices. <strong>Micro frontends</strong> have continued to gain in popularity since they were first introduced. We've seen many teams adopt some form of this architecture as a way to manage the complexity of multiple developers and teams contributing to the same user experience. In June of last year, one of the originators of this technique published an <a href=""https://martinfowler.com/articles/micro-frontends.html"">introductory article</a> that serves as a reference for micro frontends. It shows how this style can be implemented using various web programming mechanisms and builds out an example application using <a href=""/radar/languages-and-frameworks/react-js"">React.js</a>. We're confident this style will grow in popularity as larger organizations try to decompose UI development across multiple teams.</p>"
Pipelines as code,Adopt,Techniques,FALSE,"<p>The <strong>pipelines as code</strong> technique emphasizes that the configuration of delivery pipelines that build, test and deploy our applications or infrastructure should be treated as code; they should be placed under source control and modularized in reusable components with automated testing and deployment. As organizations move to decentralized autonomous teams building <a href=""https://martinfowler.com/articles/microservices.html"">microservices</a> or <a href=""/radar/techniques/micro-frontends"">micro frontends</a>, the need for engineering practices in managing pipelines as code increases to keep building and deploying software consistent within the organization. This need has given rise to delivery pipeline templates and tooling that enable a standardized way to build and deploy services and applications. Such tools use the <em>declarative delivery pipelines</em> of applications, adopting a pipeline blueprint to execute the underlying tasks for various stages of a delivery lifecycle such as build, test and deployment; and they abstract away implementation details. The ability to build, test and deploy pipelines as code should be one of the evaluation criteria for choosing a CI/CD tool.</p>"
Pragmatic remote pairing,Adopt,Techniques,TRUE,"<p>We firmly believe that <a href=""https://martinfowler.com/articles/on-pair-programming.html"">pair programming</a> improves the quality of code, spreads knowledge throughout a team and allows overall faster delivery of software. In a post COVID-19 world, however, many software teams will be distributed or fully remote, and in this situation we recommend <strong>pragmatic remote pairing</strong>: adjusting pairing practices to what's possible given the tools at hand. Consider tools such as <a href=""/radar/tools/visual-studio-live-share"">Visual Studio Live Share</a> for efficient, low-latency collaboration. Only resort to pixel-sharing if both participants reside in relative geographic proximity and have high-bandwidth internet connections. Pair developers who are in similar time zones rather than expecting pairing to work between participants regardless of their location. If pairing isn't working for logistical reasons, fall back to practices such as individual programming augmented via code reviews, pull-request collaboration (but beware <a href=""/radar/techniques/long-lived-branches-with-gitflow"">long-lived branches with Gitflow</a>) or shorter pairing sessions for critical parts of the code. We've engaged in remote pairing for years, and we've found it to be effective if done with a dose of pragmatism.</p>"
Simplest possible feature toggle,Adopt,Techniques,TRUE,"<p>Unfortunately, <a href=""https://martinfowler.com/articles/feature-toggles.html"">feature toggles</a> are less common than we'd like, and quite often we see people mixing up its types and use cases. It's quite common to come across teams that use heavyweight platforms such as <a href=""https://launchdarkly.com/"">LaunchDarkly</a> to implement feature toggles, including release toggles, to benefit from <a href=""https://martinfowler.com/articles/continuousIntegration.html"">Continuous Integration</a>, when all you need are if/else conditionals. Therefore, unless you need A/B testing or <a href=""https://martinfowler.com/bliki/CanaryRelease.html"">canary release</a> or hand over feature release responsibility to business folks, we encourage you to use the <strong>simplest possible feature toggle</strong> instead of unnecessarily complex feature toggle frameworks.</p>"
Continuous delivery for machine learning (CD4ML),Trial,Techniques,FALSE,"<p>Applying machine learning to make the business applications and services intelligent is more than just training models and serving them. It requires implementing end-to-end and continuously repeatable cycles of training, testing, deploying, monitoring and operating the models. <strong><a href=""https://martinfowler.com/articles/cd4ml.html"">Continuous delivery for machine learning (CD4ML)</a></strong> is a technique that enables reliable end-to-end cycles of development, deploying and monitoring machine learning models. The underpinning technology stack to enable CD4ML includes tooling for accessing and discovering data, version control of artefacts (such as data, model and code), continuous delivery pipelines, automated environment provisioning for various deployments and experiments, model performance assessment and tracking, and model operational observability. Companies can choose their own tool set depending on their existing tech stack. CD4ML emphasizes automation and removing manual handoffs. CD4ML is our de facto approach for developing ML models.</p>"
Ethical bias testing,Trial,Techniques,FALSE,"<p>Over the past year, we've seen a shift in interest around machine learning and deep neural networks in particular. Until now, tool and technique development has been driven by excitement over the remarkable capabilities of these models. Currently, though, there is rising concern that these models could cause unintentional harm. For example, a model could be trained inadvertently to make profitable credit decisions by simply excluding disadvantaged applicants. Fortunately, we're seeing a growing interest in <strong>ethical bias testing</strong> that will help to uncover potentially harmful decisions. Tools such as <a href=""https://github.com/marcotcr/lime"">lime</a>, <a href=""https://aif360.mybluemix.net/"">AI Fairness 360</a> or <a href=""/radar/tools/what-if-tool"">What-If Tool</a> can help uncover inaccuracies that result from underrepresented groups in training data and visualization tools such as <a href=""https://ai.googleblog.com/2017/07/facets-open-source-visualization-tool.html"">Google Facets</a> or <a href=""https://pair-code.github.io/facets/"">Facets Dive</a> can be used to discover subgroups within a corpus of training data. We've used lime (local interpretable model-agnostic explanations) in addition to this technique in order to understand the predictions of any machine-learning classifier and what classifiers (or models) are doing.</p>"
GraphQL for server-side resource aggregation,Trial,Techniques,FALSE,"<p>We see more and more tools such as <a href=""https://www.apollographql.com/docs/apollo-server/federation/introduction/"">Apollo Federation</a> that can aggregate multiple GraphQL endpoints into a single graph. However, we caution against misusing <a href=""/radar/languages-and-frameworks/graphql"">GraphQL</a>, especially when turning it into a server-to-server protocol. Our practice is to use <strong><a href=""/radar/techniques/graphql-for-server-side-resource-aggregation"">GraphQL for server-side resource aggregation</a></strong> only. When using this pattern, the microservices continue to expose well-defined RESTful APIs, while under-the-hood aggregate services or <a href=""/radar/techniques/bff-backend-for-frontends"">BFF (Backend for Frontends)</a> patterns use GraphQL resolvers as the implementation for stitching resources from other services. The shape of the graph is driven by domain-modeling exercises to ensure ubiquitous language is limited to subgraphs where needed (in the case of one-microservice-per-bounded-context). This technique simplifies the internal implementation of aggregate services or BFFs, while encouraging good modeling of services to avoid <a href=""/radar/techniques/anemic-rest"">anemic REST</a>.</p>"
Micro frontends for mobile,Trial,Techniques,TRUE,"<p>Since introducing it in the Radar in 2016, we've seen widespread adoption of <a href=""/radar/techniques/micro-frontends"">micro frontends</a> for web UIs. Recently, however, we've seen projects extend this architectural style to include <strong>micro frontends for mobile</strong> applications as well. When the application becomes sufficiently large and complex, it becomes necessary to distribute the development over multiple teams. This presents the challenge of maintaining team autonomy while integrating their work into a single app. Although we've seen teams writing their own frameworks to enable this development style, existing modularization frameworks such as <a href=""/radar/languages-and-frameworks/atlas-and-beehive"">Atlas and Beehive</a> can also simplify the problem of integrating multiteam app development.</p>"
Platform engineering product teams,Trial,Techniques,FALSE,"<p>The adoption of cloud and DevOps — while increasing the productivity of teams who can now move more quickly with reduced dependency on centralized operations teams and infrastructure — also has constrained teams that lack the skills to self-manage a full application and operations stack. Some organizations have tackled this challenge by creating <strong>platform engineering product teams</strong>. These teams maintain an internal platform that enables delivery teams to deploy and operate systems with reduced lead time and stack complexity. The emphasis here is on API-driven self-service and supporting tools, with delivery teams still responsible for supporting what they deploy onto the platform. Organizations that consider establishing such a platform team should be very cautious not to accidentally create a <a href=""/radar/techniques/separate-devops-team"">separate DevOps team</a>, nor should they simply relabel their <a href=""/radar/platforms/superficial-private-cloud"">existing hosting and operations structure</a> as a platform. If you're wondering how to best set up platform teams, we've been using the concepts from <a href=""https://teamtopologies.com/"">Team Topologies</a> to split platform teams in our projects into enablement teams, core ""platform within a platform"" teams and stream-focused teams.</p>"
Security policy as code,Trial,Techniques,FALSE,"<p>Security policies are rules and procedures that protect our systems from threats and disruption. For example, access control policies define and enforce who can access which services and resources under what circumstances; or network security policies can dynamically limit the traffic rate to a particular service. The complexity of the technology landscape today demands treating <strong>security policy as code</strong>: define and keep policies under version control, automatically validate them, automatically deploy them and monitor their performance. Tools such as <a href=""/radar/tools/open-policy-agent-opa"">Open Policy Agent</a> or platforms such as <a href=""/radar/platforms/istio"">Istio</a> provide flexible policy definition and enforcement mechanisms that support the practice of security policy as code.</p>"
Semi-supervised learning loops,Trial,Techniques,FALSE,"<p><strong>Semi-supervised learning loops</strong> are a class of iterative machine-learning workflows that take advantage of the relationships to be found in unlabeled data. These techniques may improve models by combining labeled and unlabeled data sets in various ways. In other cases they compare models trained on different subsets of the data. Unlike either unsupervised learning where a machine infers classes in unlabeled data or supervised techniques where the training set is entirely labeled, semi-supervised techniques take advantage of a small set of labeled data and a much larger set of unlabeled data. Semi-supervised learning is also closely related to active learning techniques where a human is directed to selectively label ambiguous data points. Since expert humans that can accurately label data are a scarce resource and labeling is often the most time-consuming activity in the machine-learning workflow, semi-supervised techniques lower the cost of training and make machine learning feasible for a new class of users. We're also seeing the application of weakly supervised techniques where machine-labeled data is used but is trusted less than the data labeled by humans.</p>"
Transfer learning for NLP,Trial,Techniques,FALSE,"<p>We had this technique in Assess previously. The innovations in the NLP landscape continue at a great pace, and we're able to leverage these innovations in our projects thanks to the ubiquitous <strong>transfer learning for NLP</strong>. The GLUE benchmark (a suite of language understanding tasks) scores have seen dramatic progress over the past couple of years with average scores moving from 70.0 at launch to some of the leaders crossing 90.0 as of April 2020. A lot of our projects in the NLP domain are able to make significant progress by starting from pretrained models from ELMo, <a href=""/radar/techniques/bert"">BERT</a>, and <a href=""/radar/languages-and-frameworks/ernie"">ERNIE</a>, among others, and then fine-tuning them based on the project needs.</p>"
"Use ""remote native"" processes and approaches",Trial,Techniques,TRUE,"<p><a href=""https://www.martinfowler.com/articles/remote-or-co-located.html"">Distributed teams come in many shapes and setups</a>; delivery teams in a 100% single-site co-located setup, however, have become the exception for us. Most of our teams are either multisite teams or have at least some team members working off-site. Therefore, <strong>using ""remote native"" processes and approaches</strong> by default can help significantly with the overall team flow and effectiveness. This starts with making sure that everybody has access to the necessary remote systems. Moreover, using tools such as <a href=""/radar/tools/visual-studio-live-share"">Visual Studio Live Share</a>, <a href=""/radar/tools/mural"">MURAL</a> or <a href=""https://gsuite.google.com/products/jamboard/"">Jamboard</a> turn online workshops and remote pairing into routines instead of ineffective exceptions. But ""remote native"" goes beyond a lift-and-shift of co-location practices to the digital world: Embracing more asynchronous communication, even more discipline around decision documentation, and ""everybody always remote"" meetings are other approaches our teams practice by default to optimize for location fluidity.</p>"
Zero trust architecture (ZTA),Trial,Techniques,TRUE,"<p>The technology landscape of organizations today is increasingly more complex with assets — data, functions, infrastructure and users — spread across security boundaries, such as local hosts, multiple cloud providers and a variety of SaaS vendors. This demands a paradigm shift in enterprise security planning and systems architecture, moving from static and slow-changing security policy management, based on trust zones and network configurations, to dynamic, fine-grained security policy enforcement based on temporal access privileges.</p>

<p><strong>Zero trust architecture (ZTA)</strong> is an organization's strategy and journey to implement zero-trust security principles for all of their assets — such as devices, infrastructure, services, data and users — and includes implementing practices such as securing all access and communications regardless of the network location, enforcing policies as code based on the least privilege and as granular as possible, and continuous monitoring and automated mitigation of threats. Our Radar reflects many of the enabling techniques such as <a href=""/radar/techniques/security-policy-as-code"">security policy as code</a>, <a href=""/radar/techniques/sidecars-for-endpoint-security"">sidecars for endpoint security</a> and <a href=""/radar/techniques/beyondcorp"">BeyondCorp</a>. If you're on your journey toward ZTA, refer to the <a href=""https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-207-draft2.pdf"">NIST ZTA publication</a> to learn more about principles, enabling technology components and migration patterns as well as Google's publication on <a href=""https://cloud.google.com/security/beyondprod"">BeyondProd</a>.</p>"
Data mesh,Assess,Techniques,FALSE,"<p><strong><a href=""https://martinfowler.com/articles/data-monolith-to-mesh.html"">Data mesh</a></strong> is an architectural and organizational paradigm that challenges the age-old assumption that we must centralize big analytical data to use it, have data all in one place or be managed by a centralized data team to deliver value. Data mesh claims that for big data to fuel innovation, its ownership must be federated among domain data owners who are accountable for providing their data as products (with the support of a self-serve data platform to abstract the technical complexity involved in serving data products);  it must also adopt a new form of federated governance through automation to enable interoperability of domain-oriented data products. Decentralization, along with interoperability and focus on the experience of data consumers, are key to the democratization of innovation using data.</p>

<p>If your organization has a large number of domains with numerous systems and teams generating data or a diverse set of data-driven use cases and access patterns, we suggest you assess data mesh. Implementation of data mesh requires investment in building a self-serve data platform and embracing an organizational change for domains to take on the long-term ownership of their data products, as well as an incentive structure that rewards domains serving and utilizing data as a product.</p>"
Decentralized identity,Assess,Techniques,TRUE,"<p>Since the birth of the internet, the technology landscape has experienced an accelerated evolution toward decentralization. While protocols such as HTTP and architectural patterns such as <a href=""https://martinfowler.com/articles/microservices.html"">microservices</a> or <a href=""/radar/techniques/data-mesh"">data mesh</a> enable decentralized implementations, identity management remains centralized. The emergence of distributed ledger technology (DLT), however, provides the opportunity to enable the concept of <strong>decentralized identity</strong>. In a decentralized identity system, entities — that is, discrete identifiable units such as people, organizations and things — are free to use any shared root of trust. In contrast, conventional identity management systems are based on centralized authorities and registries such as corporate directory services, certificate authorities or domain name registries.</p>

<p>The development of <a href=""https://www.w3.org/TR/did-core/"">decentralized identifiers</a> — globally unique, persistent and <em>self-sovereign identifiers</em> that are cryptographically verifiable — is a major enabling standard. Although scaled implementations of decentralized identifiers in the wild are still rare, we're excited by the premise of this movement and have started using the concept in our architecture. For the latest experiments and industry collaborations, check out <a href=""https://identity.foundation/"">Decentralized Identity Foundation</a>.</p>"
Declarative data pipeline definition,Assess,Techniques,TRUE,"<p>Many data pipelines are defined in a large, more or less imperative script written in Python or Scala. The script contains the logic of the individual steps as well as the code chaining the steps together. When faced with a similar situation in Selenium tests, developers discovered the Page Object pattern, and later many behavior-driven development (BDD) frameworks implemented a split between step definitions and their composition. Some teams are now experimenting with bringing the same thinking to data engineering. A separate <strong>declarative data pipeline definition</strong>, maybe written in YAML, contains only the declaration and sequence of steps. It states input and output data sets but refers to scripts if and when more complex logic is needed. With <a href=""https://github.com/binaryaffairs/a-la-mode"">A La Mode</a>, we're seeing the first open source tool appear in this space.</p>"
DeepWalk,Assess,Techniques,TRUE,"<p><strong><a href=""https://github.com/phanein/deepwalk"">DeepWalk</a></strong> is an algorithm that helps apply machine learning on graphs. When working on data sets that are represented as graphs, one of the key problems is to extract features from the graph. This is where DeepWalk can help. It uses SkipGram to construct node embeddings by viewing the graph as a language where each node is a unique word in the language and random walks of finite length on the graph constitutes a sentence. These embeddings can then be used by various ML models. DeepWalk is one of the techniques we're trialling on some of our projects where we've needed to apply machine learning on graphs.</p>"
Managing stateful systems via container orchestration,Assess,Techniques,TRUE,"<p>We recommend caution in <strong>managing stateful systems via container orchestration</strong> platforms such as Kubernetes. Some databases are not built with native support for orchestration — they don't expect a scheduler to kill and relocate them to a different host. Building a highly available service on top of such databases is not trivial, and we still recommend running them on bare metal hosts or a virtual machine (VM) rather than to force-fit them into a container orchestration platform.</p>"
Preflight builds,Assess,Techniques,TRUE,"<p>Even though we strongly advocate in favor of CI rather than <a href=""/radar/techniques/gitflow"">Gitflow</a>, we know that <a href=""https://trunkbaseddevelopment.com/committing-straight-to-the-trunk/"">committing straight to the trunk</a> and running the CI on a master branch can be ineffective if the team is too big, the builds are slow or flaky, or the team lacks the discipline to run the full test suite locally. In this situation a red build can block multiple devs or pairs of devs. Instead of fixing the underlying root cause — slow builds, the inability to run tests locally or monolithic architectures that necessitate many people working in the same area — teams usually rely on feature branches to bypass these issues. We discourage feature branches, given they may require significant effort to resolve merge conflicts, and they introduce longer feedback loops and potential bugs during conflict resolution. Instead, we propose using <strong>preflight builds</strong> as an alternative: these are pull request–based builds for “micro branches” that live only for the duration of the pipeline run, with the branch opened for every commit. To help automate this workflow, we've come across bots such as <a href=""https://bors.tech/"">Bors</a>, which automates merging to master and branch deletion in case the mini branch build succeeds. We're assessing this flow, and you should too; but don't use this to solve the wrong problem, as it can lead to misuse of branches and may cause more harm than benefit.</p>"
Cloud lift and shift,Hold,Techniques,FALSE,"<p>It is rather curious, that after over a decade of industry experience with cloud migration, we still feel it's necessary to call out <strong>cloud lift and shift</strong>; a practice that views cloud simply as a hosting solution, resulting in the replication of an existing architecture, security practices and IT operational models in the cloud. This fails to realize the cloud's promises of agility and digital innovation. A cloud migration requires intentional change across multiple axes toward a cloud-native state, and depending on the unique migration circumstances, each organization might end up somewhere on the spectrum from cloud lift and shift to cloud native. Systems architecture, for example, is one of the pillars of delivery agility and often requires change. The temptation to simply <a href=""https://cloud.google.com/migrate/anthos/docs/anthos-migrate-benefits"">lift and shift existing systems as containers</a> to the cloud can be strong. While this tactic can speed up cloud migration, it falls short when it comes to creating agility and delivering features and value. Enterprise security in the cloud is fundamentally different from traditional perimeter-based security through firewalls and zoning, and it demands a journey toward <a href=""/radar/techniques/zero-trust-architecture-zta"">zero trust architecture</a>. The IT operating model too has to be reformed to safely provide cloud services through self-serve automated platforms and empower teams to take more of the operational responsibility and gain autonomy. Last but not least, organizations must build a foundation to enable continuous change, such as creating pipelines with continuous testing of applications and infrastructure as a part of the migration. These will help the migration process, result in a more robust and well-factored system and give organizations a way to continue to evolve and improve their systems.</p>"
Legacy migration feature parity,Hold,Techniques,FALSE,"<p>We find that more and more organizations need to replace aging legacy systems to keep up with the demands of their customers (both internal and external). One antipattern we keep seeing is <strong>legacy migration feature parity</strong> , the desire to retain feature parity with the old. We see this as a huge missed opportunity. Often the old systems have bloated over time, with many features unused by users (50% according to a <a href=""https://www.standishgroup.com/sample_research_files/Exceeding%20Value_Layout.pdf"">2014 Standish Group report</a>) and business processes that have evolved over time. Replacing these features is a waste. Our advice: Convince your customers to take a step back and understand what their users currently <em>need</em> and prioritize these needs against business outcomes and metrics — which often is easier said than done. This means conducting user research and applying modern product development practices rather than simply replacing the existing ones.</p>"
Log aggregation for business analytics,Hold,Techniques,TRUE,"<p>Several years ago, a new generation of log aggregation platforms emerged that were capable of storing and searching over vast amounts of log data to uncover trends and insights in operational data. <a href=""/radar/tools/splunk"">Splunk</a> was the most prominent but by no means the only example of these tools. Because these platforms provide broad operational and security visibility across the entire estate of applications, administrators and developers have grown increasingly dependent on them. This enthusiasm spread as stakeholders discovered that they could use <strong>log aggregation for business analytics</strong>. However, business needs can quickly outstrip the flexibility and usability of these tools. Logs intended for technical observability are often inadequate to infer deep customer understanding. We prefer either to use tools and metrics designed for customer analytics or to take a more event-driven approach to observability where both business and operational events are collected and stored in a way they can be replayed and processed by more purpose-built tools.</p>"
Long-lived branches with Gitflow,Hold,Techniques,FALSE,"<p>Five years ago we highlighted the problems with <strong>long-lived branches with Gitflow</strong>. Essentially, long-lived branches are the opposite of continuously integrating all changes to the source code, and in our experience continuous integration is the better approach for most kinds of software development. Later we extended our caution to <a href=""/radar/techniques/gitflow"">Gitflow</a> itself, because we saw teams using it almost exclusively with long-lived branches. Today, we still see teams in settings where continuous delivery of web-based systems is the stated goal being drawn to long-lived branches. So we were delighted that the author of Gitflow has now added a note to his <a href=""https://nvie.com/posts/a-successful-git-branching-model/"">original article</a>, explaining that Gitflow was not intended for such use cases.</p>"
Snapshot testing only,Hold,Techniques,TRUE,"<p>The value of snapshot testing is undeniable when working with legacy systems by ensuring that the system continues to work and the legacy code doesn't break. However, we're seeing the common, rather harmful practice of using <strong>snapshot testing only</strong> as the primary test mechanism. Snapshot tests validate the exact result generated in the DOM by a component, not the component's behavior; therefore, it can be weak and unreliable, fostering the ""only delete the snapshot and regenerate it"" bad practice. Instead, you should test the logic and behavior of the components emulating what users would do. This mindset is encouraged by tools in the <a href=""https://testing-library.com/docs/guiding-principles"">Testing Library</a> family.</p>"
.NET Core,Adopt,Platforms,FALSE,"<p>We previously had <strong>.NET Core</strong> in Adopt, indicating that it had become our default for .NET projects. But we felt it's worth again calling attention to .NET Core. With the release of .NET Core 3.<em>x</em> last year, the bulk of the features from .NET Framework have now been ported into .NET Core. With the announcement that <a href=""https://devblogs.microsoft.com/dotnet/introducing-net-5"">.NET Framework is on its last release</a>, Microsoft have reinforced the view that <a href=""https://devblogs.microsoft.com/dotnet/net-core-is-the-future-of-net/"">.NET Core is the future of .NET</a>. Microsoft has done a lot of work to make .NET Core <a href=""https://devblogs.microsoft.com/dotnet/using-net-and-docker-together-dockercon-2019-update/"">container friendly</a>. Most of our .NET Core–based projects target Linux and are often deployed as containers. The upcoming <a href=""https://devblogs.microsoft.com/dotnet/introducing-net-5/"">.NET 5</a> release looks promising, and we're looking forward to it.</p>"
Istio,Adopt,Platforms,FALSE,"<p>If you're building and operating a scaled <a href=""https://martinfowler.com/articles/microservices.html"">microservices</a> architecture and have embraced <a href=""/radar/platforms/kubernetes"">Kubernetes</a>, adopting <a href=""/radar/techniques/service-mesh"">service mesh</a> to manage all cross-cutting aspects of running the architecture is a default position. Among various implementations of service mesh, <strong><a href=""https://istio.io"">Istio</a></strong> has gained majority adoption. It has a rich feature set, including service discovery, traffic management, service-to-service and origin-to-service security, observability (including telemetry and distributed tracing), rolling releases and resiliency. Its user experience has been improved in its latest releases, because of its ease of installation and control panel architecture. Istio has lowered the bar for implementing large-scale microservices with operational quality for many of our clients, while admitting that operating your own Istio and Kubernetes instances requires adequate knowledge and internal resources which is not for the fainthearted.</p>"
Anka,Trial,Platforms,FALSE,"<p><strong><a href=""https://ankadoc.bitbucket.io/"">Anka</a></strong> is a set of tools to create, manage, distribute, build and test macOS reproducible virtual environments for iOS and macOS. It brings Docker-like experience to macOS environments: instant start, CLI to manage virtual machines and registry to version and tag virtual machines for distribution. We've used Anka to build a macOS private cloud for a client. This tool is worth considering when virtualizing iOS and macOS environments.</p>"
Argo CD,Trial,Platforms,TRUE,"<p>Without making a judgment of the GitOps technique, we'd like to talk about <strong><a href=""https://argoproj.github.io/argo-cd/"">Argo CD</a></strong> within the scope of deploying and monitoring applications in <a href=""/radar/platforms/kubernetes"">Kubernetes</a> environments. Based on its ability to automate the deployment of the desired application state in the specified target environments in Kubernetes and our good experience with troubleshooting failed deployments, verifying logs and monitoring deployment status, we recommend you give Argo CD a try. You can even see graphically what is going on in the cluster, how a change is propagated and how pods are created and destroyed in real time.</p>"
Crowdin,Trial,Platforms,FALSE,"<p>Most of the projects with multilingual support start with development teams building features in one language and managing the rest through offline translation via emails and spreadsheets. Although this simple setup works, things can quickly get out of hand. You may have to keep answering the same questions for different language translators, sucking the energy out of the collaboration between translators, proofreaders and the development team. <strong><a href=""https://crowdin.com"">Crowdin</a></strong> is one of a handful of platforms that help in streamlining the localization workflow of your project. With Crowdin the development team can continue building features, while the platform streamlines the text that needs translation into an online workflow. We like that Crowdin nudges the teams to continuously and incrementally incorporate translations rather than managing them in large batches toward the end.</p>"
eBPF,Trial,Platforms,TRUE,"<p>For several years now, the Linux kernel has included the extended Berkeley Packet Filter (<strong>eBPF</strong>) virtual machine and provided the ability to attach eBPF filters to particular sockets. But <em>extended</em> BPF goes far beyond packet filtering and allows custom scripts to be triggered at various points within the kernel with very little overhead. Although this technology isn't new, it's now coming into its own with the increasing use of microservices deployed as orchestrated containers. Service-to-service communications can be complex in these systems, making it difficult to correlate latency or performance issues back to an API call. We're now seeing tools released with prewritten eBPF scripts for collecting and visualizing packet traffic or reporting on CPU utilization. With the rise of <a href=""/radar/platforms/kubernetes"">Kubernetes</a>, we’re seeing a new generation of security enforcement and instrumentation based on eBPF scripts that help tame the complexity of a large microservices deployment.</p>"
Firebase,Trial,Platforms,TRUE,"<p>Google's <strong><a href=""https://firebase.google.com/"">Firebase</a></strong> has undergone significant evolution since we mentioned it as part of a <a href=""/radar/techniques/serverless-architecture"">serverless architecture</a> in 2016. Firebase is a comprehensive platform for building mobile and web apps in a way that's supported by Google's underlying scalable infrastructure. We particularly like Firebase App Distribution, which makes it easy to publish test versions of an app via a CD pipeline, and Firebase Remote Config, which allows configuration changes to be dynamically pushed to apps without needing to republish them.</p>"
Hot Chocolate,Trial,Platforms,FALSE,"<p>The <a href=""/radar/languages-and-frameworks/graphql"">GraphQL</a> ecosystem and community keep growing. <strong><a href=""https://hotchocolate.io/"">Hot Chocolate</a></strong> is a GraphQL server for .NET (Core and Classic). It lets you build and host schemas and then serve queries against them using the same base components of GraphQL — data loader, resolver, schema, operations and types. The team behind Hot Chocolate has recently added schema stitching, which allows for a single entry point to query across multiple schemas aggregated from different locations. Despite the potential to misuse this approach, our teams are happy with Hot Chocolate — it’s well documented, and we're able to deliver value quickly to our clients.</p>"
Hydra,Trial,Platforms,FALSE,"<p>Not everyone needs a self-hosted OAuth2 solution, but if you do, have a look at <strong><a href=""https://www.ory.sh/hydra/"">Hydra</a></strong> — a fully compliant open source OAuth2 server and OpenID connect provider. Hydra has in-memory storage support for development and a relational database (PostgreSQL) for production use cases. Hydra as such is stateless and easy to scale horizontally in platforms such as <a href=""/radar/platforms/kubernetes"">Kubernetes</a>. Depending on your performance requirement, you may have to tune the number of database instances while scaling Hydra instances. And because Hydra doesn't provide any identity management solutions out of the box, you can integrate whatever flavor of identity management you have with Hydra through a clean API. This clear separation of identity from the rest of the OAuth2 framework makes it easier to integrate Hydra with an existing authentication ecosystem.</p>"
OpenTelemetry,Trial,Platforms,FALSE,"<p><strong><a href=""https://opentelemetry.io/"">OpenTelemetry</a></strong> is an open source observability project that merges <a href=""https://opentracing.io/"">OpenTracing</a> and <a href=""https://github.com/census-instrumentation"">OpenCensus</a>. The OpenTelemetry project includes <a href=""https://github.com/open-telemetry/opentelemetry-specification"">specification</a>, libraries, agents, and other components needed to capture telemetry from services to better observe, manage and debug them. It covers the three pillars of observability — distributed tracing, metrics and logging (currently in beta) — and its specification connects these three pieces through <a href=""https://github.com/open-telemetry/opentelemetry-specification/blob/master/specification/correlationcontext/api.md"">correlations</a>; thus you can use <em>metrics</em> to pinpoint a problem, locate the corresponding <em>traces</em> to discover where the problem occured, and ultimately study the corresponding <em>logs</em> to find the exact root cause. OpenTelemetry components can be connected to back-end observability systems such as <a href=""/radar/tools/prometheus"">Prometheus</a> and <a href=""/radar/tools/jaeger"">Jaeger</a> among <a href=""https://opentelemetry.io/registry/?s=exporter"">others</a>. Formation of OpenTracing is a positive step toward the convergence of standardization and the simplification of tooling.</p>"
Snowflake,Trial,Platforms,FALSE,"<p><strong><a href=""https://www.snowflake.com"">Snowflake</a></strong> has proven to be a robust SaaS big data storage, warehouse or lake solution for many of our clients. It has a superior architecture to scale storage, compute, and services to load, unload and use data. It's also very flexible: it supports storage of structured, semi-structured and unstructured data; provides a growing list of <a href=""https://docs.snowflake.com/en/user-guide/conns-drivers.html"">connectors</a> for different access patterns such as Spark for data science and SQL for analytics; and runs on multiple cloud providers. Our advice to many of our clients is to use managed services for their utility technology such as big data storage; however, if the risk and regulations prohibit the use of managed services, then Snowflake is a good candidate for companies with large volumes of data and heavy processing workloads. Although we've been successful using Snowflake in our medium-sized engagements, we've yet to experience Snowflake in large ecosystems where data need to be owned across segments of the organization.</p>"
Anthos,Assess,Platforms,TRUE,"<p>We see a shift from accidental hybrid or whole-of-estate cloud migration plans to intentional and sophisticated hybrid, poly or portable cloud strategies, where organizations apply multidimensional principles to establish and execute their cloud strategy: where to host their various data and functional assets based on risk, ability to control and performance profiles; how to utilize their on-premise infrastructure investments while reducing the cost of operations; and how to take advantage of multiple cloud providers and their unique differentiated services without creating complexity and friction for users building and operating applications.</p>

<p><strong><a href=""https://cloud.google.com/anthos"">Anthos</a></strong> is Google's answer to enable hybrid and multicloud strategies by providing a high-level management and control plane on top of a set of open source technologies such as <a href=""https://cloud.google.com/anthos/gke"">GKE</a>, <a href=""https://cloud.google.com/anthos/service-mesh"">Service Mesh</a> and a Git-based <a href=""https://cloud.google.com/anthos/config-management"">Configuration Management</a>. It enables running portable workloads and other assets on different hosting environments, including Google Cloud and on-premises hardware. Although other cloud providers have comparative offerings, Anthos intends to go beyond a hybrid cloud to a portable cloud enabler using open source components, but that is yet to be seen. We're seeing a rising interest in Anthos. While Google's approach in managed hybrid cloud environments seems promising, it’s not a magic bullet and requires changes in both existing cloud and on-premise assets. Our advice for clients considering Anthos is to make measured tradeoffs between selecting services from the Google Cloud ecosystem and other options, to maintain their right level of neutrality and control.</p>"
Apache Pulsar,Assess,Platforms,TRUE,"<p><strong><a href=""https://pulsar.apache.org/en/"">Apache Pulsar</a></strong> is an open source pub-sub messaging/streaming platform, competing in a similar space with <a href=""/radar/tools/apache-kafka"">Apache Kafka</a>. It provides expected functionality — such as low-latency async and sync message delivery and scalable persistent storage of messages — as well as various client libraries. What has excited us to evaluate Pulsar is its ease of scalability, particularly in large organizations with multiple segments of users. Pulsar natively supports multitenancy, georeplication, role-based access control and segregation of billing. We're also looking to Pulsar to solve the problem of a never-ending log of messages for our large-scale data systems where events are expected to persist indefinitely and subscribers are able to start consuming messages retrospectively. This is supported through a <a href=""https://pulsar.apache.org/docs/en/concepts-tiered-storage/"">tiered storage</a> model. Although Pulsar is a promising platform for large organizations, there is room for improvement. Its current installation requires administering <a href=""https://pulsar.apache.org/docs/en/administration-zk-bk/"">ZooKeeper and BookKeeper</a> among other pieces of technology. We hope that with its growing adoption, users can soon count on wider community support.</p>"
Cosmos,Assess,Platforms,TRUE,"<p>The performance of blockchain technology has been greatly improved since we <a href=""/radar/techniques/blockchain-beyond-bitcoin"">initially assessed</a> this area in the Radar. However, there's still no single blockchain that could achieve ""internet-level"" throughput. As various blockchain platforms develop, we're seeing new data and value silos. That's why cross-chain tech has always been a key topic in the blockchain community: the future of blockchain may be a network of independent parallel blockchains. This is also the vision of <strong><a href=""https://cosmos.network/"">Cosmos</a></strong>. Cosmos releases <a href=""/radar/platforms/tendermint"">Tendermint</a> and CosmosSDK to let developers customize independent blockchains. These parallel blockchains could exchange value through the Inter-Blockchain Communication (IBC) protocol and Peg-Zones. Our teams have had great experiences with CosmosSDK, and the IBC protocol is maturing. This architecture could solve blockchain interoperability and scalability issues.</p>"
Google BigQuery ML,Assess,Platforms,TRUE,"<p>Often training and predicting outcomes from machine learning models require code to take the data to the model. <strong><a href=""https://cloud.google.com/bigquery-ml/docs"">Google BigQuery ML</a></strong> inverts this by bringing the model to the data. <a href=""https://cloud.google.com/bigquery"">Google BigQuery</a> is a data warehouse designed to serve large-scale queries using SQL, for analytical use cases. Google BigQuery ML extends this function and its SQL interface to create, train and evaluate machine learning models using its data sets; and eventually run model predictions to create new BigQuery data sets. It supports a limited set of models out of the box, such as linear regression for forecasting or binary and multiclass regression for classification. It also supports, with limited functionality, importing previously trained <a href=""/radar/languages-and-frameworks/tensorflow"">TensorFlow</a> models. Although BigQuery ML and its SQL-based approach lower the bar for using machine learning to make predictions and recommendations, particularly for quick explorations, this comes with a difficult trade-off: compromising on other aspects of model training such as <a href=""/radar/techniques/ethical-bias-testing"">ethical bias testing</a>, <a href=""/radar/techniques/explainability-as-a-first-class-model-selection-criterion"">explainability</a> and <a href=""/radar/techniques/continuous-delivery-for-machine-learning-cd4ml"">continuous delivery for machine learning</a>.</p>"
JupyterLab,Assess,Platforms,TRUE,"<p><strong><a href=""https://jupyterlab.readthedocs.io/en/stable/getting_started/overview.html"">JupyterLab</a></strong> is the next-generation web-based user interface for Project <a href=""/radar/tools/jupyter"">Jupyter</a>. If you've been using Jupyter Notebooks, JupyterLab is worth a try; it gives you an interactive environment for Jupyter notebooks, code and data. We see it as an evolution of Jupyter Notebook: it provides a better experience by extending its original capabilities of allowing code, visualization and documentation to exist in one place.</p>"
Marquez,Assess,Platforms,TRUE,"<p><strong><a href=""https://marquezproject.github.io/marquez/"">Marquez</a></strong> is a relatively young open source project for collecting and serving metadata information about a data ecosystem. It represents a simple data model to capture metadata such as lineage, upstream and downstream data processing jobs and their status, and a flexible set of tags to capture the attributes of data sets. It provides a simple <a href=""https://marquezproject.github.io/marquez/openapi.html#"">RESTful API</a> to manage the metadata which eases the integration of Marquez to other tool sets within the data ecosystem.</p>

<p>We've used Marquez as a starting point and easily extended it to fit our needs such as enforcing security policies as well as changes to its domain language. If you're looking for a small and simple tool to bootstrap storage and visualization of your data-processing jobs and data sets, Marquez is a good place to start.</p>"
Matomo,Assess,Platforms,TRUE,"<p><strong><a href=""https://matomo.org"">Matomo</a></strong> (formerly Piwik) is an open source web analytics platform that provides you with full control over your data. You can self-host Matomo and secure your web analytics data from third parties. Matomo also makes it easy to integrate web analytics data with your in-house data platform and lets you build usage models that are tailored to your needs.</p>"
MeiliSearch,Assess,Platforms,TRUE,"<p><strong><a href=""https://github.com/meilisearch/MeiliSearch"">MeiliSearch</a></strong> is a fast, easy-to-use and easy-to-deploy text search engine. Over the years Elasticsearch has become the popular choice for scalable text searches. However, if you don't have the volume of data that warrants a distributed solution but still want to provide a fast typo-tolerant search engine, then we recommend assessing MeiliSearch.</p>"
Stratos,Assess,Platforms,TRUE,"<p>Ultraleap (previously Leap Motion) has been a leader in the XR space for some time, creating remarkable hand-tracking hardware that allows a user's hands to make the leap into virtual reality. <strong><a href=""https://www.ultraleap.com/haptics/"">Stratos</a></strong> is Ultraleap's underlying haptics, sensors and software platform, and it can use targeted ultrasound to create haptic feedback in mid-air. A use case is responding to a driver's hand gesture to change the air conditioning in the car and providing haptic feedback as part of the interface. We're excited to see this technology and what creative technologists might do to incorporate it into their use cases.</p>"
Trillian,Assess,Platforms,TRUE,"<p><strong><a href=""https://github.com/google/trillian"">Trillian</a></strong> is a cryptographically verifiable, centralized data store. For trustless, decentralized environments, you can use blockchain-based distributed ledgers. For enterprise environments, however, where the cost of CPU-heavy consensus protocols is unwarranted, we recommend you give Trillian a try.</p>"
Node overload,Hold,Platforms,TRUE,"<p>Technologies, especially wildly popular ones, have a tendency to be overused. What we're seeing at the moment is <strong>Node overload</strong>, a tendency to use Node.js indiscriminately or for the wrong reasons. Among these, two stand out in our opinion. Firstly, we frequently hear that Node should be used so that all programming can be done in one programming language. Our view remains that <a href=""/radar/techniques/polyglot-programming"">polyglot programming</a> is a better approach, and this still goes <a href=""/radar/languages-and-frameworks/javascript-as-a-first-class-language"">both ways</a>. Secondly, we often hear teams cite performance as a reason to choose Node.js. Although there are myriads of more or less sensible benchmarks, this perception is rooted in history. When Node.js became popular, it was the first major framework to embrace a nonblocking programming model which made it very efficient for IO-heavy tasks. (We mentioned this in our write-up of Node.js in 2012.) Due to its single-threaded nature, Node.js was never a good choice for compute-heavy workloads, though, and now that capable nonblocking frameworks also exist on other platforms — some with elegant, modern APIs — performance is no longer a reason to choose Node.js.</p>"
Cypress,Adopt,Tools,FALSE,"<p><strong><a href=""http://www.cypress.io/"">Cypress</a></strong> is still a favorite among our teams where developers manage end-to-end tests themselves, as part of a healthy <a href=""https://martinfowler.com/articles/practical-test-pyramid.html#End-to-endTests"">test pyramid</a>, of course. We decided to call it out again in this Radar because recent versions of Cypress have added <a href=""https://cypress.io/blog/2020/02/06/introducing-firefox-and-edge-support-in-cypress-4-0/"">support for Firefox</a>, and we strongly suggest testing on multiple browsers. The dominance of Chrome and Chromium-based browsers has led to a worrying trend of teams seemingly only testing with Chrome which can lead to <a href=""https://twitter.com/mike_conley/status/1245797292453609478"">nasty surprises</a>.</p>"
Figma,Adopt,Tools,FALSE,"<p><strong><a href=""https://www.figma.com/"">Figma</a></strong> has demonstrated to be the go-to tool for collaborative design, not only for designers but for multidisciplinary teams too; it allows developers and other roles to view and comment on designs through the browser without the desktop version. Compared to its competitors (e.g., Invision or Sketch) which have you use more than one tool for versioning, collaborating and design sharing, Figma puts together all of these features in one tool that makes it easier for our teams to discover new ideas together. Our teams find Figma very useful, especially in remote and distributed design work enablement and facilitation. In addition to its real-time design and collaboration capabilities, Figma also offers an API that helps to improve the <a href=""/radar/techniques/designops"">DesignOps</a> process.</p>"
Dojo,Trial,Tools,TRUE,"<p>A few years ago, Docker — and containers in general — radically changed how we think about packaging, deploying and running our applications. But despite this improvement in production, developers still spend a lot of time setting up development environments and regularly run into ""but it works on my machine"" style problems. <strong><a href=""https://github.com/kudulab/dojo"">Dojo</a></strong> aims to fix this by creating standard development environments, versioned and released as Docker images. Several of our teams use Dojo to streamline developing, testing and building code from local development through production pipelines.</p>"
DVC,Trial,Tools,TRUE,"<p>In 2018 we mentioned <strong><a href=""https://dvc.org/"">DVC</a></strong> in conjunction with the <a href=""/radar/techniques/versioning-data-for-reproducible-analytics"">versioning data for reproducible analytics</a>. Since then it has become a favorite tool for managing experiments in machine learning (ML) projects. Since it's based on Git, DVC is a familiar environment for software developers to bring their engineering practices to ML practice. Because it versions the code that processes data along with the data itself and tracks stages in a pipeline, it helps bring order to the modeling activities without interrupting the analysts’ flow.</p>"
Experiment tracking tools for machine learning,Trial,Tools,FALSE,"<p>The day-to-day work of machine learning often boils down to a series of experiments in selecting a modeling approach and the network topology, training data and optimizing or tweaking the model. Data scientists must use experience and intuition to hypothesize changes and then measure the impact those changes have on the overall performance of the model. As this practice has matured, our teams have found an increasing need for <strong>experiment tracking tools for machine learning</strong>. These tools help investigators keep track of the experiments and work through them methodically. Although no clear winner has emerged, tools such as <a href=""https://mlflow.org/"">MLflow</a> and platforms such as <a href=""https://comet.ml"">Comet</a> or <a href=""https://neptune.ml"">Neptune</a> have introduced rigor and repeatability into the entire machine learning workflow.</p>"
Goss,Trial,Tools,TRUE,"<p>We mentioned <strong><a href=""https://github.com/aelsabbahy/goss"">Goss</a></strong>, a tool for <a href=""/radar/techniques/provisioning-testing"">provisioning testing</a>, in passing in previous Radars, for example, when describing the technique of <a href=""/radar/techniques/tdd-ing-containers"">TDD'ing containers</a>. Although Goss isn't always an alternative to <a href=""/radar/tools/serverspec"">Serverspec</a>, simply because it doesn't offer the same amount of features, you may want to consider it when its features meet your needs, especially since it comes as a small, self-contained binary (rather than requiring a Ruby environment). A common anti-pattern with using tools such as Goss is double-entry bookkeeping, where each change in the actual infrastructure as code files requires a corresponding change in the test assertions. Such tests are maintenance heavy and because of the close correspondence between code and test, failures mostly occur when an engineer updates one side and forgets the other. And these tests rarely catch genuine problems.</p>"
Jaeger,Trial,Tools,FALSE,"<p><strong><a href=""https://github.com/jaegertracing/jaeger"">Jaeger</a></strong> is an open source distributed tracing system. Similar to <a href=""/radar/tools/zipkin"">Zipkin</a>, it's been inspired by the Google <a href=""https://ai.google/research/pubs/pub36356"">Dapper</a> paper and complies with <a href=""/radar/platforms/opentelemetry"">OpenTelemetry</a>. We've used Jaeger successfully with <a href=""/radar/platforms/istio"">Istio</a> and <a href=""https://www.envoyproxy.io/"">Envoy</a> on Kubernetes and like its <a href=""https://github.com/jaegertracing/jaeger-ui"">UI</a>. Jaeger exposes tracing metrics in the <a href=""/radar/tools/prometheus"">Prometheus</a> format so they can be made available to other tools. However, a new generation of tools such as <a href=""/radar/tools/honeycomb"">Honeycomb</a> integrates traces and metrics into a single observability stream for simpler aggregate analysis. Jaeger joined <a href=""https://www.cncf.io/blog/2017/09/13/cncf-hosts-jaeger/"">CNCF</a> in 2017 and has recently been elevated to CNCF's highest level of maturity, indicating its widespread deployment into production systems.</p>"
k9s,Trial,Tools,TRUE,"<p>We continue to be ardent supporters of <a href=""/radar/techniques/infrastructure-as-code"">infrastructure as code</a>, and we continue to believe that a robust monitoring solution is a prerequisite for operating distributed applications. Sometimes an interactive tool such as the AWS web console can be a useful addition. It allows us to explore all kinds of resources in an ad-hoc fashion without having to remember every single obscure command. Using an interactive tool to make manual modifications on the fly is still a questionable practice, though. For <a href=""/radar/platforms/kubernetes"">Kubernetes</a> we now have <strong><a href=""https://k9scli.io/"">k9s</a></strong>, which provides an interactive interface for basically everything that kubectl can do. And to boot, it's not a web application but runs inside a terminal window, evoking fond memories of <a href=""https://en.wikipedia.org/wiki/Midnight_Commander"">Midnight Commander</a> for some of us.</p>"
kind,Trial,Tools,TRUE,"<p><strong><a href=""https://github.com/kubernetes-sigs/kind"">kind</a></strong> is a tool for running local <a href=""/radar/platforms/kubernetes"">Kubernetes</a> clusters using Docker container nodes. With <a href=""https://github.com/kubernetes/test-infra/tree/master/kubetest"">kubetest</a> integration, kind makes it easy to do end-to-end testing on Kubernetes. We've used kind to create ephemeral Kubernetes clusters to test Kubernetes resources such as Operators and Custom Resource Definitions (CRDs) in our CI pipelines.</p>"
mkcert,Trial,Tools,TRUE,"<p><strong><a href=""https://github.com/FiloSottile/mkcert"">mkcert</a></strong> is a convenient tool for creating locally trusted development certificates. Using certificates from real certificate authorities (CAs) for local development can be challenging if not impossible (for hosts such as example.test, localhost or 127.0.0.1). In such situations self-signed certificates may be your only option. mkcert lets you generate self-signed certificates and installs the local CA in the system root store. For anything other than local development and testing, we strongly recommend using certificates from real CAs to avoid trust issues.</p>"
MURAL,Trial,Tools,TRUE,"<p><strong><a href=""https://www.mural.co/"">MURAL</a></strong> describes itself as a ""digital workspace for visual collaboration"" and allows teams to interact with a shared workspace based on a whiteboard/sticky notes metaphor. Its features include voting, commenting, notes and ""follow the presenter."" We particularly like the template feature that allows a facilitator to design and then reuse guided sessions with a team. Each of the major collaboration suites have a tool in this space (for example, <a href=""https://jamboard.google.com/"">Google Jamboard</a> and <a href=""https://www.microsoft.com/en-ca/microsoft-365/microsoft-whiteboard/digital-whiteboard-app"">Microsoft Whiteboard</a>) and these are worth investigating, but we've found MURAL to be slick, effective and flexible.</p>"
Open Policy Agent (OPA),Trial,Tools,FALSE,"<p><strong><a href=""https://www.openpolicyagent.org/"">Open Policy Agent (OPA)</a></strong> has rapidly become a favorable component of many distributed cloud-native solutions that we build for our clients. OPA provides a uniform framework and <a href=""https://www.openpolicyagent.org/docs/latest/#rego"">language</a> for declaring, enforcing and controlling policies for various components of a cloud-native solution. It's a great example of a tool that implements <a href=""/radar/techniques/security-policy-as-code"">security policy as code</a>. We've had a smooth experience using OPA in multiple scenarios, including deploying resources to K8s clusters, enforcing access control across services in a <a href=""/radar/techniques/service-mesh"">service mesh</a> and fine-grained security controls as code for accessing application resources. A recent commercial offering, <a href=""https://www.styra.com/"">Styra's Declarative Authorization Service (DAS)</a>, eases the adoption of OPA for enterprises by adding a management tool, or control plane, to OPA for K8s with a prebuilt policy library, impact analysis of the policies and logging capabilities. We look forward to maturity and extension of OPA beyond operational services to (big) data-centric solutions.</p>"
Optimal Workshop,Trial,Tools,FALSE,"<p>UX research demands data collection and analysis to make better decisions about the products we need to build. Our teams find <strong><a href=""https://www.optimalworkshop.com"">Optimal Workshop</a></strong> useful because it makes it easy to validate prototypes and configure tests for data collection and thus make better decisions. Features such as first-click, card sorting, or a heatmap of user interaction help to both validate prototypes and improve website navigation and information display. It's an ideal tool for distributed teams since it allows them to conduct remote research.</p>"
Phrase,Trial,Tools,TRUE,"<p>As mentioned in our description of <a href=""/radar/platforms/crowdin"">Crowdin</a>, you now have a choice of platforms to manage the translation of a product into multiple languages instead of emailing large spreadsheets. Our teams report positive experiences with <strong><a href=""https://phrase.com/"">Phrase</a></strong>, emphasizing that it's easy to use for all key user groups. Translators use a convenient browser-based UI. Managers can add new fields and synchronize translations with other teams in the same UI. Developers can access Phrase locally and from a build pipeline. A feature that deserves a specific mention is the ability to apply versioning to translations through tags, which makes it possible to compare the look of different translations inside the actual product.</p>"
ScoutSuite,Trial,Tools,FALSE,"<p><strong><a href=""https://github.com/nccgroup/ScoutSuite"">ScoutSuite</a></strong> is an expanded and updated tool based on Scout2 (featured in the Radar in 2018) that provides security posture assessment across <a href=""/radar/platforms/aws"">AWS</a>, <a href=""/radar/platforms/azure"">Azure</a>, <a href=""/radar/platforms/google-cloud-platform"">GCP</a> and other cloud providers. It works by automatically aggregating configuration data for an environment and applying rules to audit the environment. We've found this very useful across projects for doing point-in-time security assessments.</p>"
Visual regression testing tools,Trial,Tools,FALSE,"<p>Since we first mentioned <strong>visual regression testing tools</strong> in 2014, the use of the technique has spread and the tools landscape has evolved. <a href=""/radar/tools/backstopjs"">BackstopJS</a> remains an excellent choice with new features being added regularly, including support for running inside Docker containers. <a href=""/radar/tools/loki"">Loki</a> was featured in our previous Radar. <a href=""https://applitools.com/"">Applitools</a>, <a href=""https://crossbrowsertesting.com/"">CrossBrowserTesting</a> and <a href=""https://percy.io/"">Percy</a> are SaaS solutions. Another notable mention is <a href=""https://github.com/rsmbl"">Resemble.js</a>, an image diffing library. Although most teams use it indirectly as part of BackstopJS, some of our teams have been using it to analyze and compare images of web pages directly. In general, our experience shows that visual regression tools are less useful in the early stages when the interface goes through significant changes, but they certainly prove their worth as the product matures and the interface stabilizes.</p>"
Visual Studio Live Share,Trial,Tools,FALSE,"<p><strong><a href=""https://marketplace.visualstudio.com/items?itemName=MS-vsliveshare.vsliveshare-pack"">Visual Studio Live Share</a></strong> is a suite of extensions for <a href=""/radar/tools/visual-studio-code"">Visual Studio Code</a> and Visual Studio. At a time when teams are searching for good remote collaboration options, we want to call attention to the excellent tooling here. Live Share provides a good, low-latency remote-pairing experience, and requires significantly less bandwidth than the brute-force approach of sharing your entire desktop. Importantly, developers can work with their preferred configuration, extensions and key mappings during a pairing session. In addition to real-time collaboration for editing and debugging code, Live Share allows voice calls and sharing terminals and servers.</p>"
Apache Superset,Assess,Tools,TRUE,"<p><strong><a href=""https://superset.apache.org/"">Apache Superset</a></strong> is a great business intelligence (BI) tool for data exploration and visualization to work with large data lake and data warehouse setups. It works, for example, with <a href=""/radar/platforms/presto"">Presto</a>, <a href=""https://aws.amazon.com/athena/"">Amazon Athena</a> and <a href=""https://aws.amazon.com/redshift/"">Amazon Redshift</a> and can be nicely integrated with enterprise authentication. Moreover, you don't have to be a data engineer to use it; it’s meant to benefit all engineers exploring data in their everyday work. It's worth pointing out that Apache Superset is currently undergoing incubation at the Apache Software Foundation (ASF), meaning it's not yet fully endorsed by ASF.</p>"
AsyncAPI,Assess,Tools,TRUE,"<p>Open standards are one of the foundational pillars of building distributed systems. For example, the <a href=""https://github.com/OAI"">OpenAPI (formerly Swagger)</a> specification, as an industry standard to define RESTful APIs, has been instrumental to the success of distributed architectures such as <a href=""https://martinfowler.com/articles/microservices.html"">microservices</a>. It has enabled a proliferation of tooling to support building, testing and monitoring RESTful APIs. However, such standardizations have been largely missing in distributed systems for <a href=""https://martinfowler.com/articles/201701-event-driven.html"">event-driven APIs</a>.</p>

<p><strong><a href=""https://www.asyncapi.com/"">AsyncAPI</a></strong> is an open source initiative to create a much needed event-driven and asynchronous API standardization and development tooling. The <a href=""https://www.asyncapi.com/docs/specifications/2.0.0/"">AsyncAPI specification</a>, inspired by the OpenAPI specification, describes and documents event-driven APIs in a machine-readable format. It's protocol agnostic, so it can be used for APIs that work over many protocols, including MQTT, WebSockets, and Kafka. We're eager to see the ongoing improvements of AsyncAPI and further maturity of its tooling ecosystem.</p>"
ConfigCat,Assess,Tools,TRUE,"<p>If you're looking for a service to support dynamic feature toggles (and bear in mind that simple feature toggles work well too), check out <strong><a href=""https://configcat.com/"">ConfigCat</a></strong>. We'd describe it as ""like LaunchDarkly but cheaper and a bit less fancy"" and find that it does most of what we need. ConfigCat supports simple feature toggles, user segmentation, and A/B testing and has a generous free tier for low-volume use cases or those just starting out.</p>"
Gitpod,Assess,Tools,TRUE,"<p>You can build most software following a simple two-step process: check out a repository, and then run a single build script. The process of setting up a full coding environment can still be cumbersome, though. <strong><a href=""https://www.gitpod.io/"">Gitpod</a></strong> addresses this by providing cloud-based, ""ready-to-code"" environments for Github or GitLab repositories. It offers an IDE based on Visual Studio Code that runs inside the web browser. By default, these environments are launched on the Google Cloud Platform, although you can also deploy on-premise solutions. We see the immediate appeal, especially for open source software where this approach can lower the bar for casual contributors. However, it remains to be seen how viable this approach will be in corporate environments.</p>"
Gloo,Assess,Tools,TRUE,"<p>With the increasing adoption of <a href=""/radar/platforms/kubernetes"">Kubernetes</a> and <a href=""/radar/techniques/service-mesh"">service mesh</a>, API gateways have been experiencing an existential crisis in cloud-native distributed systems. After all, many of their capabilities (such as traffic control, security, routing and observability) are now provided by the cluster’s ingress controller and mesh gateway. <strong><a href=""https://www.solo.io/products/gloo/"">Gloo</a></strong> is a lightweight API gateway that embraces this change; it uses <a href=""https://www.envoyproxy.io/"">Envoy</a> as its gateway technology, while providing added value such as a cohesive view of the APIs to the external users and applications. It also provides an administrative interface for controlling Envoy gateways and runs and integrates with multiple service mesh implementations such as <a href=""https://linkerd.io/"">Linkerd</a>, <a href=""/radar/platforms/istio"">Istio</a> and <a href=""https://aws.amazon.com/app-mesh/"">AWS App Mesh</a>. While its open source implementation provides the basic capabilities expected from an API gateway, its enterprise edition has a more mature set of security controls such as API key management or integration with <a href=""/radar/tools/open-policy-agent-opa"">OPA</a>. Gloo is a promising lightweight API gateway that plays well with the ecosystem of cloud-native technology and architecture, while avoiding the API gateway trap of enabling business logic to glue APIs for the end user.</p>"
Lens,Assess,Tools,TRUE,"<p>One of the strengths of <a href=""/radar/platforms/kubernetes"">Kubernetes</a> is its flexibility and range of configuration possibilities along with the API-driven, programmable configuration mechanisms and command-line visibility and control using manifest files. However, that strength can also be a weakness: when deployments are complex or when managing multiple clusters, it can be difficult to get a clear picture of the overall status through command-line arguments and manifests alone. <strong><a href=""https://k8slens.dev/"">Lens</a></strong> attempts to solve this problem with an integrated environment for viewing the current state of the cluster and its workloads, visualizing cluster metrics and changing configurations through an embedded text editor. Rather than a simple point-and-click interface, Lens brings together the tools an administrator would run from the command line into a single, navigable interface. This tool is one of several approaches that are trying to tame the complexity of Kubernetes management. We've yet to see a clear winner in this space, but Lens strikes an interesting balance between a graphical UI and command-line–only tools.</p>"
Manifold,Assess,Tools,TRUE,"<p><strong><a href=""https://github.com/uber/manifold"">Manifold</a></strong> is a model-agnostic visual debugger for machine learning (ML). Model developers spend a significant amount of time on iterating and improving an existing model rather than creating a new one. By shifting the focus from model space to data space, Manifold supplements the existing performance metrics with a visual characteristics of the data set that influences the model performance. We think Manifold will be a useful tool to assess in the ML ecosystem.</p>"
Sizzy,Assess,Tools,TRUE,"<p>Building web applications that look just as intended on a large number of devices and screen sizes can be cumbersome. <strong><a href=""https://sizzy.co/"">Sizzy</a></strong> is a SaaS solution that shows many viewports in a single browser window. The application is rendered in all viewports simultaneously and interactions with the application are also synched across the viewports. In our experience interacting with an application in this way can make it easier to spot potential issues earlier, before a <a href=""/radar/tools/visual-regression-testing-tools"">visual regression testing tool</a> flags the issue in the build pipeline. We should mention, though, that some of our developers who tried Sizzy for a while did, on balance, prefer to work with the tooling provided by Chrome.</p>"
Snowpack,Assess,Tools,TRUE,"<p><strong><a href=""https://www.snowpack.dev/"">Snowpack</a></strong> is an interesting new entrant in the field of JavaScript build tools. The key improvement over other solutions is that Snowpack makes it possible to build applications with modern frameworks such as <a href=""/radar/languages-and-frameworks/react-js"">React.js</a>, <a href=""/radar/languages-and-frameworks/vue-js"">Vue.js</a>, and <a href=""/radar/languages-and-frameworks/angular"">Angular</a> without the need for a bundler. Cutting out the bundling step dramatically improves the feedback cycle during development because changes become available in the browser almost immediately. For this magic to work, Snowpack transforms the dependencies in <code>node_modules</code> into single JavaScript files in a new <code>web_modules</code> directory, from where they can be imported as an ECMAScript module (ESM). For IE11 and other browsers that don't support ESM, a workaround is available. Unfortunately, because no browser today can import CSS from JavaScript, using CSS modules is <a href=""https://www.snowpack.dev/#importing-css"">not straightforward</a>.</p>"
tfsec,Assess,Tools,TRUE,"<p>Security is everyone's concern and capturing risks early is always better than facing problems later on. In the <a href=""/radar/techniques/infrastructure-as-code"">infrastructure as code</a> space, where <a href=""/radar/tools/terraform"">Terraform</a> is an obvious choice to manage cloud environments, we now also have <strong><a href=""https://github.com/liamg/tfsec"">tfsec</a></strong>, which is a static analysis tool that helps to scan Terraform templates and find any potential security issues. It comes with preset rules for different cloud providers including <a href=""/radar/platforms/aws"">AWS</a> and <a href=""/radar/platforms/azure"">Azure</a>. We always like tools that help to mitigate security risks, and tfsec not only excels in identifying security risks, it's also easy to install and use.</p>"
React Hooks,Adopt,languages-and-frameworks,FALSE,"<p><strong><a href=""https://reactjs.org/docs/hooks-intro.html"">React Hooks</a></strong> have introduced a new approach to managing stateful logic; given React components have always been closer to functions than classes, Hooks have embraced this and brought state to the functions, instead of taking function as methods to the state with classes. Based on our experience, Hooks improve reuse of functionality among components and code readability. Given Hooks’ testability improvements, using <a href=""https://reactjs.org/docs/test-renderer.html"">React Test Renderer</a> and <a href=""/radar/languages-and-frameworks/react-testing-library"">React Testing Library</a>, and their growing community support, we consider them our approach of choice.</p>"
React Testing Library,Adopt,languages-and-frameworks,FALSE,"<p>The JavaScript world moves pretty fast, and as we gain more experience using a framework our recommendations change. The <strong><a href=""https://testing-library.com/"">React Testing Library</a></strong> is a good example of a framework that with deeper usage has eclipsed the alternatives to become the sensible default when testing React-based frontends. Our teams like the fact that tests written with this framework are less brittle than with alternative frameworks such as <a href=""/radar/languages-and-frameworks/enzyme"">Enzyme</a>, because you're encouraged to test component relationships individually as opposed to testing all implementation details. This mindset is brought by <a href=""https://testing-library.com/"">Testing Library</a> which React Testing Library is part of and which provides a whole family of libraries for <a href=""/radar/languages-and-frameworks/angular"">Angular</a> and <a href=""/radar/languages-and-frameworks/vue-js"">Vue.js</a>, for example.</p>"
Vue.js,Adopt,languages-and-frameworks,FALSE,"<p><strong><a href=""https://vuejs.org/"">Vue.js</a></strong> has become one of the successfully applied, loved and trusted frontend JavaScript frameworks among our community. Although there are other, well-adopted alternatives, such as <a href=""/radar/languages-and-frameworks/react-js"">React.js</a>, the simplicity of Vue.js in API design, its clear segregation of directives and components (one file per component idiom) and its simpler state management have made it a compelling option among others.</p>"
CSS-in-JS,Trial,languages-and-frameworks,FALSE,"<p>Since we first mentioned <strong>CSS-in-JS</strong> as an emerging technique in 2017, it has become much more popular, a trend we also see in our work. With some solid production experience under our belts, we can now recommend CSS-in-JS as a technique to trial. A good starting point is the <a href=""/radar/languages-and-frameworks/styled-components"">styled components</a> framework, which we mentioned in our previous Radar. Next to all the positives, though, there usually is a downside when using CSS-in-JS: the calculation of styles at runtime can cause a <a href=""https://calendar.perfplanet.com/2019/the-unseen-performance-costs-of-css-in-js-in-react-apps/"">noticeable lag for end users</a>. With <a href=""https://linaria.now.sh/"">Linaria</a> we're now seeing a new class of frameworks that were created with this issue in mind. Linaria employs a number of techniques to shift most of the performance overhead to build time. Alas, this does come with its own set of trade-offs, most notably a lack of dynamic style support in IE11.</p>"
Exposed,Trial,languages-and-frameworks,TRUE,"<p>Through their extended use of <a href=""/radar/languages-and-frameworks/kotlin"">Kotlin</a>, our development teams have gained experience with more frameworks designed specifically for Kotlin rather than using Java frameworks with Kotlin. Although it's been around for a while, <strong><a href=""https://github.com/JetBrains/Exposed"">Exposed</a></strong> has caught our attention as a lightweight object-relational mapper (ORM). Exposed has two flavors of database access: a typesafe internal DSL wrapping SQL and an implementation of the data access object (DAO) pattern. It supports features expected from a mature ORM such as handling of many-to-many references, eager loading, and support for joins across entities. We also like that the implementation works without proxies and doesn't rely on reflection, which is certainly beneficial to performance.</p>"
GraphQL Inspector,Trial,languages-and-frameworks,TRUE,"<p><strong><a href=""https://github.com/kamilkisiela/graphql-inspector"">GraphQL Inspector</a></strong> lets you compare changes between two GraphQL schemas. We've <a href=""/radar/languages-and-frameworks/graphql"">cautioned against the use of GraphQL</a> in the past, and we're happy to see some improvements in tooling around GraphQL since. Most of our teams continue to use <a href=""/radar/techniques/graphql-for-server-side-resource-aggregation"">GraphQL for server-side resource aggregation</a>, and by integrating GraphQL Inspector in their CI pipelines, we've been able to catch potential breaking changes in the GraphQL schema.</p>"
Karate,Trial,languages-and-frameworks,FALSE,"<p>Given our experience that tests are the only API specifications that really matter, we're always on the lookout for new tools that might help with testing. <strong><a href=""https://intuit.github.io/karate/"">Karate</a></strong> is an API testing framework whose unique feature is that tests are written in Gherkin-based syntax without relying on a general-purpose programming language to implement test behavior. Karate uses a domain-specific language for describing HTTP-based API tests. Our teams like the readable specification that they get with this tool and recommend to keep tests with Karate in the upper levels of the <a href=""https://martinfowler.com/articles/practical-test-pyramid.html"">testing pyramid</a> and not overload its use by making very detailed assertions.</p>"
Koin,Trial,languages-and-frameworks,TRUE,"<p>As <a href=""/radar/languages-and-frameworks/kotlin"">Kotlin</a> is used increasingly for both mobile and server-side development, the associated ecosystem continues to evolve. <strong><a href=""https://insert-koin.io/"">Koin</a></strong> is a Kotlin framework that handles one of the routine problems in software development: dependency injection. Although you can choose from a variety of dependency injection frameworks for Kotlin, our teams have come to prefer the simplicity of Koin. Koin avoids using annotations and injects either through constructors or by mimicking Kotlin's lazy initialization so that objects are injected only when needed. This is in contrast to the statically compiled <a href=""/radar/languages-and-frameworks/dagger"">Dagger</a> injection framework for Android. Our developers like the lightweight nature of this framework and its built-in testability.</p>"
NestJS,Trial,languages-and-frameworks,FALSE,"<p>The growth in popularity of Node.js and trends such as <a href=""/radar/platforms/node-overload"">Node overload</a> have led to the application of Node.js for developing business applications. We often see problems, such as scalability and maintainability, with large JavaScript-based applications. <strong><a href=""https://nestjs.com/"">NestJS</a></strong> is a <a href=""/radar/languages-and-frameworks/typescript"">TypeScript-first</a> framework that makes the development of Node.js applications safer and less error prone. NestJS is opinionated and comes with SOLID principles and an Angular-inspired architecture out of the box. When building Node.js microservices, NestJS is one of the frameworks that our teams commonly use to empower developers to create testable, scalable, loosely coupled and easily maintainable applications.</p>"
PyTorch,Trial,languages-and-frameworks,FALSE,"<p>Our teams have continued to use and appreciate the <strong><a href=""http://pytorch.org/"">PyTorch</a></strong> machine learning framework, and several teams prefer PyTorch over <a href=""/radar/languages-and-frameworks/tensorflow"">TensorFlow</a>. PyTorch exposes the inner workings of ML that TensorFlow hides, making it easier to debug, and contains constructs that programmers are familiar with such as loops and actions. Recent releases have improved performance of PyTorch, and we've been using it successfully in production projects.</p>"
Rust,Trial,languages-and-frameworks,FALSE,"<p><strong><a href=""http://www.rust-lang.org/"">Rust</a></strong> is continuously gaining in popularity. We've had heated discussions about which is better, Rust or C++/Go, without a clear winner. However, we're glad to see Rust has improved significantly, with more built-in APIs being added and stabilized, including <a href=""https://blog.rust-lang.org/2019/11/07/Async-await-stable.html"">advanced async support</a>, since we mentioned it in our previous Radar. In addition, Rust has also inspired the design of new languages. For example, the <a href=""https://developers.libra.org/docs/move-overview"">Move language</a> on Libra borrows Rust's way of managing memory to manage resources, ensuring that digital assets can never be copied or implicitly discarded.</p>"
Sarama,Trial,languages-and-frameworks,TRUE,"<p><strong><a href=""https://github.com/Shopify/sarama"">Sarama</a></strong> is a Go client library for <a href=""/radar/tools/apache-kafka"">Apache Kafka</a>. If you’re developing your APIs in Go, you'll find Sarama quite easy to set up and manage as it doesn't depend on any native libraries. Sarama has two types of APIs — a high-level API for easily producing and consuming messages and a low-level API for controlling bytes on the wire.</p>"
SwiftUI,Trial,languages-and-frameworks,FALSE,"<p>Apple has taken a big step forward with their new <strong><a href=""https://developer.apple.com/xcode/swiftui/"">SwiftUI</a></strong> framework for implementing user interfaces on the macOS and iOS platforms. We like that SwiftUI moves beyond the somewhat kludgy relationship between Interface Builder and Xcode and adopts a coherent, declarative and code-centric approach. You can now view your code and the resulting visual interface side by side in Xcode 11, making for a much better developer experience. The SwiftUI framework also draws inspiration from the <a href=""/radar/languages-and-frameworks/react-js"">React.js</a> world that has dominated web development in recent years. Immutable values in view models and an asynchronous update mechanism make for a unified reactive programming model. This gives developers an entirely native alternative to similar reactive frameworks such as <a href=""/radar/languages-and-frameworks/react-native"">React Native</a> or <a href=""/radar/languages-and-frameworks/flutter"">Flutter</a>. SwiftUI definitely represents the future of Apple UI development, and although new, it has shown its benefits. We've been having great experience with it — and its shallow learning curve. It's worth noting that you should know your customer's use case before jumping into using SwiftUI, given that it doesn't support iOS 12 or below.</p>"
Clinic.js Bubbleprof,Assess,languages-and-frameworks,TRUE,"<p>With the aim of improving performance in our code, profiling tools are very useful to identify bottlenecks or delays in code which are hard to identify, especially in asynchronous operations. <strong><a href=""https://clinicjs.org/bubbleprof/"">Clinic.js Bubbleprof</a></strong> represents visually the async operations in Node.js processes, drawing a map of delays in the application's flow. We like this tool because it helps developers to easily identify and prioritize what to improve in the code.</p>"
Deequ,Assess,languages-and-frameworks,TRUE,"<p>There are still some tool gaps when applying good software engineering practices in data engineering. Attempting to automate data quality checks between different steps in a data pipeline, one of our teams was surprised when they found only a few tools in this space. They settled on <strong><a href=""https://github.com/awslabs/deequ"">Deequ</a></strong>, a library for writing tests that resemble unit tests for data sets. Deequ is built on top of <a href=""/radar/platforms/apache-spark"">Apache Spark</a>, and even though it's published by AWS Labs it can be used in environments other than <a href=""/radar/platforms/aws"">AWS</a>.</p>"
ERNIE,Assess,languages-and-frameworks,TRUE,"<p>In the previous edition of the Radar we had <a href=""/radar/techniques/bert"">BERT</a> — which is a key milestone in the NLP landscape. Last year, Baidu released <strong><a href=""https://github.com/PaddlePaddle/ERNIE/"">ERNIE</a></strong> 2.0 (Enhanced Representation through kNowledge IntEgration) which outperformed BERT on seven GLUE language understanding tasks and on all nine of the Chinese NLP tasks. ERNIE, like BERT, provides unsupervised pretrained language models, which can be fine-tuned by adding output layers to create state-of-the-art models for a variety of NLP tasks. ERNIE differs from traditional pretraining methods in that it is a continual pretraining framework. Instead of training with a small number of pretraining objectives, it could constantly introduce a large variety of pretraining tasks to help the model efficiently learn language representations. We're pretty excited about the advancements in NLP and are looking forward to experimenting with ERNIE on our projects.</p>"
MediaPipe,Assess,languages-and-frameworks,TRUE,"<p><strong><a href=""https://github.com/google/mediapipe"">MediaPipe</a></strong> is a framework for building MultiModal (such as video, audio, time series data, etc.), cross-platform (for example, Android, iOS, Web, and edge devices) and applied ML pipelines. It provides multiple capabilities, including face detection, hand tracking, gesture detection and object detection. Although MediaPipe is primarily deployed to mobile devices, it's started to show up in the browser thanks to WebAssembly and XNNPack ML Inference Library. We're exploring MediaPipe for some AR use cases and like what we see so far.</p>"
Tailwind CSS,Assess,languages-and-frameworks,TRUE,"<p>CSS tools and frameworks offer predesigned components for fast results; after a while, however, they can complicate customization. <strong><a href=""https://tailwindcss.com/"">Tailwind CSS</a></strong> proposes an interesting approach by providing lower-level utility CSS classes to create building blocks without opinionated styles and aiming for easy customization. The breadth of the low-level utilities allows you to avoid writing any classes or CSS on your own which leads to a more maintainable codebase in the long term. It seems that Tailwind CSS offers the right balance between reusability and customization to create visual components.</p>"
Tamer,Assess,languages-and-frameworks,TRUE,"<p>If you need to ingest data from relational databases into a Kafka topic, consider <strong><a href=""https://github.com/laserdisc-io/tamer"">Tamer</a></strong>, which labels itself ""a domesticated JDBC source connector for Kafka."" Despite being a relatively new framework, we've found Tamer to be more efficient than the Kafka JDBC connector, especially when huge amounts of data are involved.</p>"
Wire,Assess,languages-and-frameworks,TRUE,"<p>The Golang community has had its fair share of dependency injection skeptics, partly because they confused the <a href=""https://martinfowler.com/articles/injection.html"">pattern</a> with specific frameworks, and developers with a system-programming background naturally dislike runtime overhead caused by reflection. Then along came <strong><a href=""https://github.com/google/wire"">Wire</a></strong>, a compile-time dependency injection tool that can generate code and wire components together. Wire has no additional runtime overhead, and the static dependency graph is easier to reason about. Whether you handwrite your code or use frameworks, we recommend using dependency injection to encourage modular and testable designs.</p>"
XState,Assess,languages-and-frameworks,TRUE,"<p>We've featured several state management libraries in the Radar before, but <strong><a href=""https://xstate.js.org/docs/"">XState</a></strong> takes a slightly different approach. It's a simple JavaScript and <a href=""/radar/languages-and-frameworks/typescript"">TypeScript</a> framework for creating finite state machines and visualizing them as state charts. It integrates with the more popular reactive JavaScript frameworks (<a href=""/radar/languages-and-frameworks/vue-js"">Vue.js</a>, <a href=""/radar/languages-and-frameworks/ember-js"">Ember.js</a>, <a href=""/radar/languages-and-frameworks/react-js"">React.js</a> and <a href=""https://rxjs.dev/"">RxJS</a>) and is based on the W3C standard for finite state machines. Another notable feature is the serialization of machine definitions. One thing that we've found helpful when creating finite state machines in other contexts (particularly when writing game logic) is the ability to visualize states and their possible transitions; we like the fact that it's really easy to do this with XState's <a href=""https://xstate.js.org/viz/"">visualizer</a>.</p>"
Enzyme,Hold,languages-and-frameworks,FALSE,"<p>We don't always move deprecated tools to Hold in the Radar, but our teams feel strongly that <strong><a href=""http://airbnb.io/enzyme/"">Enzyme</a></strong> has been replaced for unit testing <a href=""/radar/languages-and-frameworks/react-js"">React</a> UI components by <a href=""https://testing-library.com/docs/intro"">React Testing Library</a>. Teams using Enzyme have found that its focus on testing component internals leads to brittle, unmaintainable tests.</p>"